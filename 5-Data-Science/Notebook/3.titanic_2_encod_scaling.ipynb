{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data analysis and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "# visualization\n",
    "import pydotplus\n",
    "from sklearn.tree import export_graphviz\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "\n",
    "# machine learning\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Acquire data\n",
    "\n",
    "The Python Pandas packages helps us work with our datasets. We start by acquiring the training and testing datasets into Pandas DataFrames. We also combine these datasets to run certain operations on both datasets together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../../dataset/titanic/train.csv')\n",
    "test_data = pd.read_csv('../../dataset/titanic/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Exploratory Data Analysis\n",
    "\n",
    "# III. Let's build our first model : baseline\n",
    "\n",
    "# IV. Let's build improve our model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## a. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_data.copy()\n",
    "test_df = test_data.copy()\n",
    "\n",
    "#Preprocessing : with mean for train\n",
    "train_df['Age'].fillna(train_df['Age'].mean(),inplace=True)\n",
    "train_df['Embarked'].fillna('X',inplace=True)\n",
    "train_df['Cabin'].fillna('XX',inplace=True)\n",
    "train_df['Sex'] = train_df['Sex'].map({'female':0,'male':1})\n",
    "\n",
    "#categories1 = [['Sex']]\n",
    "#for cat in categories1:\n",
    "#lb = OrdinalEncoder()\n",
    "#lb.fit(X[cat])\n",
    "\n",
    "#X[cat] = lb.transform(X[cat])\n",
    "#X_test[cat] = lb.transform(X_test[cat])\n",
    "\n",
    "    \n",
    "    \n",
    "#Preprocessing : with mean for test (don't use the statistic of the test in the train!!!!!!!)\n",
    "test_df['Age'].fillna(test_df['Age'].mean(),inplace=True)\n",
    "test_df['Embarked'].fillna('X',inplace=True)\n",
    "test_df['Cabin'].fillna('XX',inplace=True)\n",
    "test_df['Sex'] = test_df['Sex'].map({'female':0,'male':1})\n",
    "test_df['Fare'].fillna(test_df['Fare'].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Feature encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For difference between get_dummies and OneHotEncoder\n",
    "#https://stackoverflow.com/questions/36631163/pandas-get-dummies-vs-sklearns-onehotencoder-what-are-the-pros-and-cons\n",
    "#One Hot encoding\n",
    "#categories2 = ['Embarked']\n",
    "#print(pd.get_dummies(X, columns=categories2))\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "encoder.fit(train_df[['Embarked']])    # Assume for simplicity all features are categorical.\n",
    "# Apply the encoder for train\n",
    "a = encoder.transform(train_df[['Embarked']])\n",
    "other = pd.DataFrame(data=a.toarray(),columns=['Embarked_1','Embarked_2','Embarked_3','Embarked_4'])\n",
    "train_df = train_df.join(other,lsuffix='_caller', rsuffix='_other')\n",
    "\n",
    "# Apply the encoder for test\n",
    "a = encoder.transform(test_df[['Embarked']])\n",
    "other = pd.DataFrame(data=a.toarray(),columns=['Embarked_1','Embarked_2','Embarked_3','Embarked_4'])\n",
    "test_df = test_df.join(other,lsuffix='_caller', rsuffix='_other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df[['Pclass', 'Sex','Age','SibSp','Parch','Fare',\n",
    "              'Embarked_1','Embarked_2','Embarked_3','Embarked_4']]\n",
    "\n",
    "sub_test = test_df[['Pclass', 'Sex','Age','SibSp','Parch','Fare',\n",
    "              'Embarked_1','Embarked_2','Embarked_3','Embarked_4']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. Feature Scaling\n",
    "<a id=\"feature_scaling\" ></a>\n",
    "***\n",
    "Feature scaling is an important concept of machine learning models. Often times a dataset contain features highly varying in magnitude and unit. For some machine learning models, it is not a problem. However, for many other ones, its quite a problem. Many machine learning algorithms uses euclidian distances to calculate the distance between two points, it is quite a problem. \n",
    "\n",
    "Some algorithms may not necessarily need feature scaling, like decision trees. In contrast, neural networks are trained via gradient-based algorithms, and so feature rescaling speeds up and stabilizes training by alleviating skew in the objective function contours that often accompanies features of varying magnitude.\n",
    "\n",
    "There are multiple ways to do feature scaling. \n",
    "<ul>\n",
    "    <li><b>MinMaxScaler</b>-Scales the data using the max and min values so that it fits between 0 and 1.</li>\n",
    "    <li><b>StandardScaler</b>-Scales the data so that it has mean 0 and variance of 1.</li>\n",
    "    <li><b>RobustScaler</b>-Scales the data similary to Standard Scaler, but makes use of the median and scales using the interquertile range so as to aviod issues with large outliers.</b>\n",
    " </ul>\n",
    "\n",
    "So, data leakage is possible when data statistics are used\n",
    "\n",
    "**Doc on line:**\n",
    "- https://sebastianraschka.com/faq/docs/scale-training-test.html\n",
    "- https://www.quora.com/Should-scaling-be-done-on-both-training-data-and-test-data-for-machine-learning-Can-one-do-scaling-on-only-the-training-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df[['Fare','SibSp','Parch','Sex']].values\n",
    "sub_test = test_df[['Fare', 'SibSp','Parch','Sex']].values\n",
    "y = train_df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprcessing of train\n",
    "scl = MinMaxScaler()\n",
    "X_scaled_minmax = scl.fit_transform(X)\n",
    "\n",
    "scl = StandardScaler()\n",
    "X_scaled_std = scl.fit_transform(X)\n",
    "\n",
    "#preprocessing of test\n",
    "scl = MinMaxScaler()\n",
    "X_test_scaled_minmax = scl.fit_transform(sub_test)\n",
    "\n",
    "scl = StandardScaler()\n",
    "X_test_scaled_std = scl.fit_transform(sub_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = X_scaled_std\n",
    "#sub_test = X_scaled_std\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5,random_state=10,shuffle=True)\n",
    "\n",
    "results_df_test = pd.DataFrame()\n",
    "results_df_train = pd.DataFrame(data=np.zeros((5,2)),columns=['Train_error', 'Test_error'])\n",
    "\n",
    "fold=0\n",
    "\n",
    "for train_index, test_index in cv.split(X, y):\n",
    "    X_train = X.loc[train_index]\n",
    "    y_train = y.loc[train_index]\n",
    "\n",
    "    X_test = X.loc[test_index]\n",
    "    y_test = y.loc[test_index]\n",
    "\n",
    "    model = KNeighborsClassifier()\n",
    "    model.fit(X_train,  y_train)\n",
    "\n",
    "    pred_sub   = model.predict_proba(sub_test)[:,1]\n",
    "    results_df_test['fold_'+str(fold)] = pred_sub\n",
    "    \n",
    "    pred_train = model.predict(X_train)\n",
    "    pred_test = model.predict(X_test)\n",
    "    \n",
    "    score = 1 - accuracy_score(y_train,pred_train)\n",
    "    results_df_train.loc[fold,'Train_error'] = round(score*100,2)\n",
    "    \n",
    "    score = 1 - accuracy_score(y_test,pred_test)    \n",
    "    results_df_train.loc[fold,'Test_error'] = round(score*100,2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    fold +=1\n",
    "\n",
    "#Mean strategy\n",
    "preds = (results_df_test.mean(axis=1) >=0.5).astype(int)\n",
    "\n",
    "my_final_sub = pd.read_csv('../../dataset/titanic/test.csv')[['PassengerId']]\n",
    "my_final_sub['Survived'] = preds\n",
    "\n",
    "my_final_sub.to_csv('submission_knn.csv', index=False)\n",
    "#Kaggle Score : 0.76076"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21773288439955107"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1- model.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Train_error    20.120\n",
       "Test_error     30.974\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_train.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sans : 0.1728395061728395\n",
    "minmax : 0.16049382716049387\n",
    "std : 0.16273849607182944\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
