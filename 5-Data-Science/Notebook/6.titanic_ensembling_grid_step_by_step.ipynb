{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data analysis and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "# visualization\n",
    "import pydotplus\n",
    "from sklearn.tree import export_graphviz\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "\n",
    "# machine learning\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "\n",
    "#preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('.\\\\titanic\\\\train.csv')\n",
    "test_data = pd.read_csv('.\\\\titanic\\\\test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_data.copy()\n",
    "test_df = test_data.copy()\n",
    "\n",
    "#Preprocessing : with mean for train\n",
    "train_df['Age'].fillna(train_df['Age'].mean(),inplace=True)\n",
    "train_df['Embarked'].fillna('X',inplace=True)\n",
    "train_df['Cabin'].fillna('XX',inplace=True)\n",
    "train_df['Sex'] = train_df['Sex'].map({'female':0,'male':1})\n",
    "train_df['Random'] = np.random.rand(train_df.shape[0])\n",
    "\n",
    "#Preprocessing : with mean for test (don't use the statistic of the test in the train!!!!!!!)\n",
    "test_df['Age'].fillna(test_df['Age'].mean(),inplace=True)\n",
    "test_df['Embarked'].fillna('X',inplace=True)\n",
    "test_df['Cabin'].fillna('XX',inplace=True)\n",
    "test_df['Sex'] = test_df['Sex'].map({'female':0,'male':1})\n",
    "test_df['Fare'].fillna(test_df['Fare'].mean(),inplace=True)\n",
    "test_df['Random'] = np.random.rand(test_df.shape[0])\n",
    "\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "encoder.fit(train_df[['Embarked']])    # Assume for simplicity all features are categorical.\n",
    "# Apply the encoder for train\n",
    "a = encoder.transform(train_df[['Embarked']])\n",
    "other = pd.DataFrame(data=a.toarray(),columns=['Embarked_1','Embarked_2','Embarked_3','Embarked_4'])\n",
    "train_df = train_df.join(other,lsuffix='_caller', rsuffix='_other')\n",
    "\n",
    "# Apply the encoder for test\n",
    "a = encoder.transform(test_df[['Embarked']])\n",
    "other = pd.DataFrame(data=a.toarray(),columns=['Embarked_1','Embarked_2','Embarked_3','Embarked_4'])\n",
    "test_df = test_df.join(other,lsuffix='_caller', rsuffix='_other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df[['Pclass', 'Sex','Age','SibSp','Parch','Fare',\n",
    "              'Embarked_1','Embarked_2','Embarked_3','Embarked_4','Random']]\n",
    "\n",
    "X_sub = test_df[['Pclass', 'Sex','Age','SibSp','Parch','Fare',\n",
    "              'Embarked_1','Embarked_2','Embarked_3','Embarked_4','Random']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprcessing of train\n",
    "scl = MinMaxScaler()\n",
    "X_scaled_minmax = scl.fit_transform(X)\n",
    "\n",
    "scl = StandardScaler()\n",
    "X_scaled_std = scl.fit_transform(X)\n",
    "\n",
    "#preprocessing of test\n",
    "scl = MinMaxScaler()\n",
    "X_sub_scaled_minmax = scl.fit_transform(X_sub)\n",
    "\n",
    "scl = StandardScaler()\n",
    "X_sub_scaled_std = scl.fit_transform(X_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "parameters_dc = { 'max_depth' : range(1,5),\n",
    "                  'min_samples_leaf': range(2,5),\n",
    "                'criterion':['entropy','gini']}\n",
    "\n",
    "gs = GridSearchCV(estimator=clf, param_grid=parameters_dc, cv=cv, n_jobs=-1 )\n",
    "_ = gs.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy', 'max_depth': 4, 'min_samples_leaf': 3}"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='entropy', max_depth=4, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=3, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Pclass', 0.12906535356000592),\n",
       " ('Sex', 0.44129993797057815),\n",
       " ('Age', 0.07555547969686437),\n",
       " ('SibSp', 0.04927503939729419),\n",
       " ('Parch', 0.037124053488259944),\n",
       " ('Fare', 0.17057425681042052),\n",
       " ('Embarked_1', 0.015590811567474995),\n",
       " ('Embarked_2', 0.009959373336185039),\n",
       " ('Embarked_3', 0.022221851764423338),\n",
       " ('Embarked_4', 0.0),\n",
       " ('Random', 0.049333842408493506)]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Estimator return by Grid search\n",
    "sorted(gs.best_estimator_.feature_importances_)\n",
    "list(zip(X.columns,gs.best_estimator_.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#It is ready for use for prediction\n",
    "gs.best_estimator_.predict(X_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.74149757, 0.25850243],\n",
       "       [0.57091136, 0.42908864],\n",
       "       [0.74149757, 0.25850243],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.64159233, 0.35840767],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.39161274, 0.60838726],\n",
       "       [0.83821466, 0.16178534],\n",
       "       [0.38719556, 0.61280444],\n",
       "       [0.82652627, 0.17347373],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.57091136, 0.42908864],\n",
       "       [0.82652627, 0.17347373],\n",
       "       [0.57091136, 0.42908864],\n",
       "       [0.5023917 , 0.4976083 ],\n",
       "       [0.74149757, 0.25850243],\n",
       "       [0.72932169, 0.27067831],\n",
       "       [0.57091136, 0.42908864],\n",
       "       [0.38719556, 0.61280444],\n",
       "       [0.8095837 , 0.1904163 ],\n",
       "       [0.73708151, 0.26291849],\n",
       "       [0.43381614, 0.56618386],\n",
       "       [0.74567576, 0.25432424],\n",
       "       [0.54258683, 0.45741317],\n",
       "       [0.82652627, 0.17347373],\n",
       "       [0.45073545, 0.54926455],\n",
       "       [0.72932169, 0.27067831],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.8095837 , 0.1904163 ],\n",
       "       [0.82652627, 0.17347373],\n",
       "       [0.82652627, 0.17347373],\n",
       "       [0.64159233, 0.35840767],\n",
       "       [0.64159233, 0.35840767],\n",
       "       [0.8095837 , 0.1904163 ],\n",
       "       [0.72932169, 0.27067831],\n",
       "       [0.43381614, 0.56618386],\n",
       "       [0.43381614, 0.56618386],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.74567576, 0.25432424],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.43381614, 0.56618386],\n",
       "       [0.57091136, 0.42908864],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.72932169, 0.27067831],\n",
       "       [0.74149757, 0.25850243],\n",
       "       [0.38719556, 0.61280444],\n",
       "       [0.53155815, 0.46844185],\n",
       "       [0.82652627, 0.17347373],\n",
       "       [0.72932169, 0.27067831],\n",
       "       [0.64159233, 0.35840767],\n",
       "       [0.64159233, 0.35840767],\n",
       "       [0.72932169, 0.27067831],\n",
       "       [0.84246059, 0.15753941],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.82652627, 0.17347373],\n",
       "       [0.38719556, 0.61280444],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.39161274, 0.60838726],\n",
       "       [0.81047966, 0.18952034],\n",
       "       [0.43381614, 0.56618386],\n",
       "       [0.39161274, 0.60838726],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.72932169, 0.27067831],\n",
       "       [0.64159233, 0.35840767],\n",
       "       [0.39161274, 0.60838726],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.43381614, 0.56618386],\n",
       "       [0.72932169, 0.27067831],\n",
       "       [0.38719556, 0.61280444],\n",
       "       [0.72932169, 0.27067831],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.57091136, 0.42908864],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.39161274, 0.60838726],\n",
       "       [0.81047966, 0.18952034],\n",
       "       [0.82652627, 0.17347373],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.74149757, 0.25850243],\n",
       "       [0.8095837 , 0.1904163 ],\n",
       "       [0.39161274, 0.60838726],\n",
       "       [0.43381614, 0.56618386],\n",
       "       [0.39161274, 0.60838726],\n",
       "       [0.83821466, 0.16178534],\n",
       "       [0.57091136, 0.42908864],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.64159233, 0.35840767],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.72932169, 0.27067831],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.57091136, 0.42908864],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.43381614, 0.56618386],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.5023917 , 0.4976083 ],\n",
       "       [0.82652627, 0.17347373],\n",
       "       [0.74149757, 0.25850243],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.54258683, 0.45741317],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.74149757, 0.25850243],\n",
       "       [0.74149757, 0.25850243],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.72932169, 0.27067831],\n",
       "       [0.39161274, 0.60838726],\n",
       "       [0.38719556, 0.61280444],\n",
       "       [0.39161274, 0.60838726],\n",
       "       [0.57091136, 0.42908864],\n",
       "       [0.8095837 , 0.1904163 ],\n",
       "       [0.72932169, 0.27067831],\n",
       "       [0.64159233, 0.35840767],\n",
       "       [0.72932169, 0.27067831],\n",
       "       [0.57091136, 0.42908864],\n",
       "       [0.43381614, 0.56618386],\n",
       "       [0.82790412, 0.17209588],\n",
       "       [0.5023917 , 0.4976083 ],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.74149757, 0.25850243],\n",
       "       [0.53155815, 0.46844185],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.50802571, 0.49197429],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.72932169, 0.27067831],\n",
       "       [0.53155815, 0.46844185],\n",
       "       [0.8095837 , 0.1904163 ],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.72932169, 0.27067831],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.43381614, 0.56618386],\n",
       "       [0.83821466, 0.16178534],\n",
       "       [0.64159233, 0.35840767],\n",
       "       [0.43381614, 0.56618386],\n",
       "       [0.81047966, 0.18952034],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.82652627, 0.17347373],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.83821466, 0.16178534],\n",
       "       [0.45073545, 0.54926455],\n",
       "       [0.72932169, 0.27067831],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.53155815, 0.46844185],\n",
       "       [0.83821466, 0.16178534],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.43381614, 0.56618386],\n",
       "       [0.43381614, 0.56618386],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.53155815, 0.46844185],\n",
       "       [0.39161274, 0.60838726],\n",
       "       [0.81047966, 0.18952034],\n",
       "       [0.43381614, 0.56618386],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.64159233, 0.35840767],\n",
       "       [0.72932169, 0.27067831],\n",
       "       [0.83821466, 0.16178534],\n",
       "       [0.38719556, 0.61280444],\n",
       "       [0.43381614, 0.56618386],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.72932169, 0.27067831],\n",
       "       [0.82652627, 0.17347373],\n",
       "       [0.72932169, 0.27067831],\n",
       "       [0.83821466, 0.16178534],\n",
       "       [0.53155815, 0.46844185],\n",
       "       [0.43381614, 0.56618386],\n",
       "       [0.8095837 , 0.1904163 ],\n",
       "       [0.53155815, 0.46844185],\n",
       "       [0.45073545, 0.54926455],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.81047966, 0.18952034],\n",
       "       [0.57091136, 0.42908864],\n",
       "       [0.74149757, 0.25850243],\n",
       "       [0.54258683, 0.45741317],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.53155815, 0.46844185],\n",
       "       [0.82652627, 0.17347373],\n",
       "       [0.64159233, 0.35840767],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.82652627, 0.17347373],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.83821466, 0.16178534],\n",
       "       [0.74149757, 0.25850243],\n",
       "       [0.73708151, 0.26291849],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.74567576, 0.25432424],\n",
       "       [0.43381614, 0.56618386],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.43381614, 0.56618386],\n",
       "       [0.39161274, 0.60838726],\n",
       "       [0.70086799, 0.29913201],\n",
       "       [0.8095837 , 0.1904163 ],\n",
       "       [0.64159233, 0.35840767],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.72932169, 0.27067831],\n",
       "       [0.39161274, 0.60838726],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.38719556, 0.61280444],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.57091136, 0.42908864],\n",
       "       [0.64159233, 0.35840767],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.39161274, 0.60838726],\n",
       "       [0.83821466, 0.16178534],\n",
       "       [0.54258683, 0.45741317],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.5023917 , 0.4976083 ],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.43381614, 0.56618386],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.38719556, 0.61280444],\n",
       "       [0.45073545, 0.54926455],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.39161274, 0.60838726],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.43381614, 0.56618386],\n",
       "       [0.82652627, 0.17347373],\n",
       "       [0.74149757, 0.25850243],\n",
       "       [0.8095837 , 0.1904163 ],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.8095837 , 0.1904163 ],\n",
       "       [0.72932169, 0.27067831],\n",
       "       [0.64159233, 0.35840767],\n",
       "       [0.5023917 , 0.4976083 ],\n",
       "       [0.38719556, 0.61280444],\n",
       "       [0.53155815, 0.46844185],\n",
       "       [0.81047966, 0.18952034],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.83821466, 0.16178534],\n",
       "       [0.82652627, 0.17347373],\n",
       "       [0.43381614, 0.56618386],\n",
       "       [0.83821466, 0.16178534],\n",
       "       [0.57091136, 0.42908864],\n",
       "       [0.5023917 , 0.4976083 ],\n",
       "       [0.64159233, 0.35840767],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.8095837 , 0.1904163 ],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.74149757, 0.25850243],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.43381614, 0.56618386],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.82652627, 0.17347373],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.53155815, 0.46844185],\n",
       "       [0.64159233, 0.35840767],\n",
       "       [0.72932169, 0.27067831],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.88762471, 0.11237529],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.43381614, 0.56618386],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.72932169, 0.27067831],\n",
       "       [0.74149757, 0.25850243],\n",
       "       [0.5023917 , 0.4976083 ],\n",
       "       [0.50802571, 0.49197429],\n",
       "       [0.72932169, 0.27067831],\n",
       "       [0.57091136, 0.42908864],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.82652627, 0.17347373],\n",
       "       [0.82652627, 0.17347373],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.43381614, 0.56618386],\n",
       "       [0.84154799, 0.15845201],\n",
       "       [0.39161274, 0.60838726],\n",
       "       [0.54258683, 0.45741317],\n",
       "       [0.64159233, 0.35840767],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.82652627, 0.17347373],\n",
       "       [0.72932169, 0.27067831],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.39161274, 0.60838726],\n",
       "       [0.72932169, 0.27067831],\n",
       "       [0.83821466, 0.16178534],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.54258683, 0.45741317],\n",
       "       [0.8095837 , 0.1904163 ],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.72932169, 0.27067831],\n",
       "       [0.73708151, 0.26291849],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.39161274, 0.60838726],\n",
       "       [0.64159233, 0.35840767],\n",
       "       [0.83821466, 0.16178534],\n",
       "       [0.74041484, 0.25958516],\n",
       "       [0.83821466, 0.16178534],\n",
       "       [0.57091136, 0.42908864],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.72932169, 0.27067831],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.39161274, 0.60838726],\n",
       "       [0.38719556, 0.61280444],\n",
       "       [0.39161274, 0.60838726],\n",
       "       [0.8095837 , 0.1904163 ],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.82652627, 0.17347373],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.72932169, 0.27067831],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.43381614, 0.56618386],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.64159233, 0.35840767],\n",
       "       [0.72932169, 0.27067831],\n",
       "       [0.82652627, 0.17347373],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.53155815, 0.46844185],\n",
       "       [0.72932169, 0.27067831],\n",
       "       [0.72932169, 0.27067831],\n",
       "       [0.54258683, 0.45741317],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.74567576, 0.25432424],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.72932169, 0.27067831],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.83821466, 0.16178534],\n",
       "       [0.45073545, 0.54926455],\n",
       "       [0.83821466, 0.16178534],\n",
       "       [0.43381614, 0.56618386],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.38719556, 0.61280444],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.43381614, 0.56618386],\n",
       "       [0.45073545, 0.54926455],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.83821466, 0.16178534],\n",
       "       [0.63939468, 0.36060532],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.57091136, 0.42908864],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.74149757, 0.25850243],\n",
       "       [0.57091136, 0.42908864],\n",
       "       [0.83821466, 0.16178534],\n",
       "       [0.54258683, 0.45741317],\n",
       "       [0.43381614, 0.56618386],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.5023917 , 0.4976083 ],\n",
       "       [0.64159233, 0.35840767],\n",
       "       [0.8095837 , 0.1904163 ],\n",
       "       [0.43381614, 0.56618386],\n",
       "       [0.45073545, 0.54926455],\n",
       "       [0.72932169, 0.27067831],\n",
       "       [0.82652627, 0.17347373],\n",
       "       [0.38719556, 0.61280444],\n",
       "       [0.88762471, 0.11237529],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.64159233, 0.35840767],\n",
       "       [0.38719556, 0.61280444],\n",
       "       [0.57091136, 0.42908864],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.83821466, 0.16178534],\n",
       "       [0.74149757, 0.25850243],\n",
       "       [0.74149757, 0.25850243],\n",
       "       [0.43381614, 0.56618386],\n",
       "       [0.57091136, 0.42908864],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.64159233, 0.35840767],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.74149757, 0.25850243],\n",
       "       [0.83821466, 0.16178534],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.53155815, 0.46844185],\n",
       "       [0.73708151, 0.26291849],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.83821466, 0.16178534],\n",
       "       [0.57091136, 0.42908864],\n",
       "       [0.74149757, 0.25850243],\n",
       "       [0.54258683, 0.45741317],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.74149757, 0.25850243],\n",
       "       [0.43381614, 0.56618386],\n",
       "       [0.82652627, 0.17347373],\n",
       "       [0.45073545, 0.54926455],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.8095837 , 0.1904163 ],\n",
       "       [0.72932169, 0.27067831],\n",
       "       [0.82652627, 0.17347373],\n",
       "       [0.81047966, 0.18952034],\n",
       "       [0.39161274, 0.60838726],\n",
       "       [0.64159233, 0.35840767],\n",
       "       [0.39161274, 0.60838726],\n",
       "       [0.50802571, 0.49197429],\n",
       "       [0.43381614, 0.56618386],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.38719556, 0.61280444],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.7203724 , 0.2796276 ],\n",
       "       [0.81047966, 0.18952034]])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if you need probability if they are implemented by the classifier \n",
    "gs.best_estimator_.predict_proba(X_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mean_fit_time',\n",
       " 'mean_score_time',\n",
       " 'mean_test_score',\n",
       " 'param_criterion',\n",
       " 'param_max_depth',\n",
       " 'param_min_samples_leaf',\n",
       " 'params',\n",
       " 'rank_test_score',\n",
       " 'split0_test_score',\n",
       " 'split1_test_score',\n",
       " 'split2_test_score',\n",
       " 'split3_test_score',\n",
       " 'split4_test_score',\n",
       " 'std_fit_time',\n",
       " 'std_score_time',\n",
       " 'std_test_score']"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dict of how grid shows the best parameters\n",
    "sorted(gs.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.23437791, 0.25531826, 0.25048647, 0.22739167, 0.23896108,\n",
       "        0.25895853, 0.24663401, 0.24235601, 0.22892833, 0.25795436,\n",
       "        0.228409  , 0.24816613, 0.21738577, 0.26362953, 0.26582503,\n",
       "        0.26255608, 0.24940805, 0.27808952, 0.2748569 , 0.25313292,\n",
       "        0.27717705, 0.27362156, 0.25583811, 0.20480752]),\n",
       " 'std_fit_time': array([0.01895597, 0.0265372 , 0.02745972, 0.01576914, 0.02587399,\n",
       "        0.03032495, 0.02422329, 0.01277545, 0.02167638, 0.02287248,\n",
       "        0.00725093, 0.03056918, 0.01953626, 0.02767128, 0.06261286,\n",
       "        0.04645128, 0.03967807, 0.05098158, 0.05500806, 0.042641  ,\n",
       "        0.04659947, 0.05020499, 0.02506307, 0.02303993]),\n",
       " 'mean_score_time': array([0.01515918, 0.01436143, 0.01635609, 0.0157578 , 0.01416206,\n",
       "        0.01618562, 0.01558547, 0.01628962, 0.01568456, 0.01610227,\n",
       "        0.0162025 , 0.0166069 , 0.01789594, 0.0195899 , 0.01999383,\n",
       "        0.02717571, 0.0200768 , 0.02147517, 0.02070656, 0.02099113,\n",
       "        0.023383  , 0.01549721, 0.01579771, 0.01037331]),\n",
       " 'std_score_time': array([0.00171556, 0.00101762, 0.00386785, 0.00230888, 0.00116336,\n",
       "        0.00222142, 0.00205631, 0.00107542, 0.00060084, 0.00157208,\n",
       "        0.00131202, 0.00081167, 0.00577897, 0.00665813, 0.01051083,\n",
       "        0.01617588, 0.01249255, 0.00510809, 0.00569137, 0.01014974,\n",
       "        0.01163708, 0.00141281, 0.00318345, 0.0024097 ]),\n",
       " 'param_criterion': masked_array(data=['entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 1, 1, 1, 2, 2, 2,\n",
       "                    3, 3, 3, 4, 4, 4],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_leaf': masked_array(data=[2, 3, 4, 2, 3, 4, 2, 3, 4, 2, 3, 4, 2, 3, 4, 2, 3, 4,\n",
       "                    2, 3, 4, 2, 3, 4],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'criterion': 'entropy', 'max_depth': 1, 'min_samples_leaf': 2},\n",
       "  {'criterion': 'entropy', 'max_depth': 1, 'min_samples_leaf': 3},\n",
       "  {'criterion': 'entropy', 'max_depth': 1, 'min_samples_leaf': 4},\n",
       "  {'criterion': 'entropy', 'max_depth': 2, 'min_samples_leaf': 2},\n",
       "  {'criterion': 'entropy', 'max_depth': 2, 'min_samples_leaf': 3},\n",
       "  {'criterion': 'entropy', 'max_depth': 2, 'min_samples_leaf': 4},\n",
       "  {'criterion': 'entropy', 'max_depth': 3, 'min_samples_leaf': 2},\n",
       "  {'criterion': 'entropy', 'max_depth': 3, 'min_samples_leaf': 3},\n",
       "  {'criterion': 'entropy', 'max_depth': 3, 'min_samples_leaf': 4},\n",
       "  {'criterion': 'entropy', 'max_depth': 4, 'min_samples_leaf': 2},\n",
       "  {'criterion': 'entropy', 'max_depth': 4, 'min_samples_leaf': 3},\n",
       "  {'criterion': 'entropy', 'max_depth': 4, 'min_samples_leaf': 4},\n",
       "  {'criterion': 'gini', 'max_depth': 1, 'min_samples_leaf': 2},\n",
       "  {'criterion': 'gini', 'max_depth': 1, 'min_samples_leaf': 3},\n",
       "  {'criterion': 'gini', 'max_depth': 1, 'min_samples_leaf': 4},\n",
       "  {'criterion': 'gini', 'max_depth': 2, 'min_samples_leaf': 2},\n",
       "  {'criterion': 'gini', 'max_depth': 2, 'min_samples_leaf': 3},\n",
       "  {'criterion': 'gini', 'max_depth': 2, 'min_samples_leaf': 4},\n",
       "  {'criterion': 'gini', 'max_depth': 3, 'min_samples_leaf': 2},\n",
       "  {'criterion': 'gini', 'max_depth': 3, 'min_samples_leaf': 3},\n",
       "  {'criterion': 'gini', 'max_depth': 3, 'min_samples_leaf': 4},\n",
       "  {'criterion': 'gini', 'max_depth': 4, 'min_samples_leaf': 2},\n",
       "  {'criterion': 'gini', 'max_depth': 4, 'min_samples_leaf': 3},\n",
       "  {'criterion': 'gini', 'max_depth': 4, 'min_samples_leaf': 4}],\n",
       " 'split0_test_score': array([0.79329609, 0.7877095 , 0.79329609, 0.80446927, 0.80446927,\n",
       "        0.7877095 , 0.84357542, 0.84357542, 0.84916201, 0.84357542,\n",
       "        0.84916201, 0.84916201, 0.79329609, 0.77653631, 0.7877095 ,\n",
       "        0.81005587, 0.80446927, 0.81564246, 0.84916201, 0.82681564,\n",
       "        0.84357542, 0.83240223, 0.84357542, 0.8547486 ]),\n",
       " 'split1_test_score': array([0.75280899, 0.70786517, 0.76966292, 0.75280899, 0.76966292,\n",
       "        0.7752809 , 0.7752809 , 0.76966292, 0.7752809 , 0.7752809 ,\n",
       "        0.76966292, 0.7752809 , 0.78089888, 0.71348315, 0.69662921,\n",
       "        0.76404494, 0.76966292, 0.7752809 , 0.78089888, 0.76404494,\n",
       "        0.76404494, 0.78089888, 0.76966292, 0.76966292]),\n",
       " 'split2_test_score': array([0.76404494, 0.76966292, 0.79213483, 0.80898876, 0.79775281,\n",
       "        0.81460674, 0.84831461, 0.86516854, 0.85955056, 0.86516854,\n",
       "        0.85955056, 0.85955056, 0.76966292, 0.75280899, 0.76404494,\n",
       "        0.80337079, 0.82022472, 0.79213483, 0.8258427 , 0.85955056,\n",
       "        0.85955056, 0.85393258, 0.86516854, 0.85955056]),\n",
       " 'split3_test_score': array([0.74719101, 0.73595506, 0.74157303, 0.76404494, 0.76404494,\n",
       "        0.76404494, 0.80337079, 0.80898876, 0.79213483, 0.80898876,\n",
       "        0.79775281, 0.80337079, 0.74157303, 0.73595506, 0.69662921,\n",
       "        0.76404494, 0.75842697, 0.75280899, 0.78651685, 0.7752809 ,\n",
       "        0.80337079, 0.79213483, 0.79775281, 0.78089888]),\n",
       " 'split4_test_score': array([0.80898876, 0.80337079, 0.80898876, 0.81460674, 0.82022472,\n",
       "        0.81460674, 0.83146067, 0.8258427 , 0.81460674, 0.83707865,\n",
       "        0.84269663, 0.83146067, 0.80898876, 0.80337079, 0.80337079,\n",
       "        0.82022472, 0.81460674, 0.80337079, 0.8258427 , 0.82022472,\n",
       "        0.82022472, 0.84831461, 0.84269663, 0.8258427 ]),\n",
       " 'mean_test_score': array([0.77326596, 0.76091269, 0.78113113, 0.78898374, 0.79123093,\n",
       "        0.79124976, 0.82040048, 0.82264767, 0.81814701, 0.82601845,\n",
       "        0.82376499, 0.82376499, 0.77888394, 0.75643086, 0.74967673,\n",
       "        0.79234825, 0.79347812, 0.78784759, 0.81365263, 0.80918335,\n",
       "        0.81815329, 0.82153663, 0.82377126, 0.81814073]),\n",
       " 'std_test_score': array([0.02391963, 0.03473974, 0.02341571, 0.02540511, 0.02127292,\n",
       "        0.02048774, 0.02743863, 0.03240417, 0.03225788, 0.03107286,\n",
       "        0.03431527, 0.03082684, 0.02278246, 0.0312553 , 0.04508673,\n",
       "        0.0237247 , 0.02481271, 0.02198877, 0.02595099, 0.03508993,\n",
       "        0.03319803, 0.02966652, 0.034839  , 0.03701698]),\n",
       " 'rank_test_score': array([21, 22, 19, 17, 16, 15,  7,  5,  9,  1,  3,  3, 20, 23, 24, 14, 13,\n",
       "        18, 11, 12,  8,  6,  2, 10])}"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimation score : 0.8260184545853996\n",
      "Best estimation variance 0.031072862802004695\n"
     ]
    }
   ],
   "source": [
    "# Best score\n",
    "i = np.argmin(gs.cv_results_['rank_test_score']) #index of min\n",
    "print('Best estimation score :', gs.best_score_)\n",
    "print('Best estimation variance',gs.cv_results_['std_test_score'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Pclass', 0.15604610239186528), ('Sex', 0.44369248141816064), ('Age', 0.08826883357377147), ('SibSp', 0.05031086423831988), ('Parch', 0.030235796222136273), ('Fare', 0.1824206869558377), ('Embarked_1', 0.022903039987620104), ('Embarked_2', 0.008433744386521221), ('Embarked_3', 0.017679272465906764), ('Embarked_4', 9.178359860684269e-06)]\n"
     ]
    }
   ],
   "source": [
    "# In cas you need only parameters\n",
    "a = RandomForestClassifier(**gs.best_params_)\n",
    "_ = a.fit(X,y)\n",
    "print(list(zip(X.columns.values,a.feature_importances_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Ensembling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Voting \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: DT\n",
      "Best params are: {'max_depth': 3, 'min_samples_leaf': 3, 'min_samples_split': 2}\n",
      "Best estimation score : 0.8181658401858014\n",
      "Best estimation variance 0.032567502513050496 \n",
      "\n",
      "Classifier: ET\n",
      "Best params are: {'max_depth': 3, 'min_samples_leaf': 2, 'min_samples_split': 3}\n",
      "Best estimation score : 0.8192706044818279\n",
      "Best estimation variance 0.02414906009903531 \n",
      "\n",
      "Classifier: SVC\n",
      "Best params are: {'C': 1}\n",
      "Best estimation score : 0.6812880547360491\n",
      "Best estimation variance 0.028346439925249878 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Trees Parameters\n",
    "dt_params = {\n",
    "    'max_depth': range(1,5),\n",
    "    'min_samples_leaf': range(2,5),\n",
    "    'min_samples_split':range(2,5),\n",
    "}\n",
    "# Extra Trees Parameters\n",
    "et_params = {\n",
    "    'max_depth': range(1,5),\n",
    "    'min_samples_leaf': range(2,5),\n",
    "    'min_samples_split':range(2,5),\n",
    "}\n",
    "# Support Vector Classifier parameters \n",
    "svc_params = {\n",
    "    'C' : [0,1, 0.05,0.025]\n",
    "    }\n",
    "\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "\n",
    "clf_dt = DecisionTreeClassifier()\n",
    "clf_et = ExtraTreesClassifier()\n",
    "clf_svc = SVC(probability=True)\n",
    "\n",
    "dic_clf = {\n",
    "    'DT' : [clf_dt, dt_params],\n",
    "    'ET' : [clf_et, et_params], \n",
    "    'SVC': [clf_svc, svc_params]\n",
    "}\n",
    "\n",
    "gs = {}\n",
    "\n",
    "for key in dic_clf:\n",
    "    gs[key] = GridSearchCV(estimator=dic_clf[key][0], param_grid=dic_clf[key][1], cv=cv, n_jobs=-1 )\n",
    "    _ = gs[key].fit(X,y)\n",
    "    print('Classifier:',key)\n",
    "    print('Best params are:',gs[key].best_params_)\n",
    "    i = np.argmin(gs[key].cv_results_['rank_test_score']) #index of min\n",
    "    print('Best estimation score :', gs[key].best_score_)\n",
    "    print('Best estimation variance',gs[key].cv_results_['std_test_score'][i],'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DT</th>\n",
       "      <th>ET</th>\n",
       "      <th>SVC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      DT   ET  SVC\n",
       "0    0.0  0.0  0.0\n",
       "1    0.0  0.0  0.0\n",
       "2    0.0  0.0  0.0\n",
       "3    0.0  0.0  0.0\n",
       "4    0.0  0.0  0.0\n",
       "..   ...  ...  ...\n",
       "413  0.0  0.0  0.0\n",
       "414  0.0  0.0  0.0\n",
       "415  0.0  0.0  0.0\n",
       "416  0.0  0.0  0.0\n",
       "417  0.0  0.0  0.0\n",
       "\n",
       "[418 rows x 3 columns]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test_vote = pd.DataFrame(data=np.zeros(X_sub.shape[0]*len(gs.keys())).reshape(X_sub.shape[0],len(gs.keys())),columns=gs.keys())\n",
    "pred_test_vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DT</th>\n",
       "      <th>ET</th>\n",
       "      <th>SVC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     DT  ET  SVC\n",
       "0     0   0    0\n",
       "1     1   0    0\n",
       "2     0   0    0\n",
       "3     0   0    0\n",
       "4     1   0    0\n",
       "..   ..  ..  ...\n",
       "413   0   0    0\n",
       "414   1   1    1\n",
       "415   0   0    0\n",
       "416   0   0    0\n",
       "417   0   0    0\n",
       "\n",
       "[418 rows x 3 columns]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key in gs:\n",
    "    pred_test_vote[key] = gs[key].predict(X_sub)\n",
    "pred_test_vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DT</th>\n",
       "      <th>ET</th>\n",
       "      <th>SVC</th>\n",
       "      <th>Prediction_Hard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     DT  ET  SVC  Prediction_Hard\n",
       "179   1   1    1                1\n",
       "106   0   0    0                0\n",
       "375   1   1    1                1\n",
       "60    0   0    0                0\n",
       "119   1   1    0                1\n",
       "..   ..  ..  ...              ...\n",
       "122   1   1    1                1\n",
       "74    1   1    1                1\n",
       "86    1   1    0                1\n",
       "404   0   0    0                0\n",
       "408   1   1    0                1\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Soft voting using a threshold: à.5\n",
    "\n",
    "pred_test_vote['Prediction_Hard'] = (pred_test_vote.mean(axis=1) >=0.5).astype(int)\n",
    "pred_test_vote.sample(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soft voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DT</th>\n",
       "      <th>ET</th>\n",
       "      <th>SVC</th>\n",
       "      <th>Prediction_Hard</th>\n",
       "      <th>DT_soft</th>\n",
       "      <th>ET_soft</th>\n",
       "      <th>SVC_soft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.115473</td>\n",
       "      <td>0.224091</td>\n",
       "      <td>0.286749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.589744</td>\n",
       "      <td>0.445650</td>\n",
       "      <td>0.290644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.115473</td>\n",
       "      <td>0.297253</td>\n",
       "      <td>0.292685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.115473</td>\n",
       "      <td>0.196907</td>\n",
       "      <td>0.286125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.589744</td>\n",
       "      <td>0.448295</td>\n",
       "      <td>0.296335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.115473</td>\n",
       "      <td>0.196381</td>\n",
       "      <td>0.283110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.785377</td>\n",
       "      <td>0.804601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.115473</td>\n",
       "      <td>0.193454</td>\n",
       "      <td>0.283578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.115473</td>\n",
       "      <td>0.196381</td>\n",
       "      <td>0.283282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.115473</td>\n",
       "      <td>0.295526</td>\n",
       "      <td>0.302434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     DT  ET  SVC  Prediction_Hard   DT_soft   ET_soft  SVC_soft\n",
       "0     0   0    0                0  0.115473  0.224091  0.286749\n",
       "1     1   0    0                0  0.589744  0.445650  0.290644\n",
       "2     0   0    0                0  0.115473  0.297253  0.292685\n",
       "3     0   0    0                0  0.115473  0.196907  0.286125\n",
       "4     1   0    0                0  0.589744  0.448295  0.296335\n",
       "..   ..  ..  ...              ...       ...       ...       ...\n",
       "413   0   0    0                0  0.115473  0.196381  0.283110\n",
       "414   1   1    1                1  0.980000  0.785377  0.804601\n",
       "415   0   0    0                0  0.115473  0.193454  0.283578\n",
       "416   0   0    0                0  0.115473  0.196381  0.283282\n",
       "417   0   0    0                0  0.115473  0.295526  0.302434\n",
       "\n",
       "[418 rows x 7 columns]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key in gs:\n",
    "    pred_test_vote[key+'_soft'] = gs[key].predict_proba(X_sub)[:,1]\n",
    "pred_test_vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DT</th>\n",
       "      <th>ET</th>\n",
       "      <th>SVC</th>\n",
       "      <th>Prediction_Hard</th>\n",
       "      <th>DT_soft</th>\n",
       "      <th>ET_soft</th>\n",
       "      <th>SVC_soft</th>\n",
       "      <th>Prediction_soft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.115473</td>\n",
       "      <td>0.196718</td>\n",
       "      <td>0.283413</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.589744</td>\n",
       "      <td>0.478386</td>\n",
       "      <td>0.400929</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.115473</td>\n",
       "      <td>0.230971</td>\n",
       "      <td>0.279854</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.358333</td>\n",
       "      <td>0.405110</td>\n",
       "      <td>0.768422</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.115473</td>\n",
       "      <td>0.222058</td>\n",
       "      <td>0.287090</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.115473</td>\n",
       "      <td>0.264708</td>\n",
       "      <td>0.291650</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.809693</td>\n",
       "      <td>0.605840</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.589744</td>\n",
       "      <td>0.448301</td>\n",
       "      <td>0.293761</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.264297</td>\n",
       "      <td>0.397746</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.115473</td>\n",
       "      <td>0.294393</td>\n",
       "      <td>0.289507</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     DT  ET  SVC  Prediction_Hard   DT_soft   ET_soft  SVC_soft  \\\n",
       "163   0   0    0                0  0.115473  0.196718  0.283413   \n",
       "117   1   0    0                0  0.589744  0.478386  0.400929   \n",
       "121   0   0    0                0  0.115473  0.230971  0.279854   \n",
       "306   0   0    1                0  0.358333  0.405110  0.768422   \n",
       "271   0   0    0                0  0.115473  0.222058  0.287090   \n",
       "..   ..  ..  ...              ...       ...       ...       ...   \n",
       "321   0   0    0                0  0.115473  0.264708  0.291650   \n",
       "364   1   1    1                1  0.980000  0.809693  0.605840   \n",
       "412   1   0    0                0  0.589744  0.448301  0.293761   \n",
       "201   1   0    0                0  1.000000  0.264297  0.397746   \n",
       "336   0   0    0                0  0.115473  0.294393  0.289507   \n",
       "\n",
       "     Prediction_soft  \n",
       "163                0  \n",
       "117                0  \n",
       "121                0  \n",
       "306                1  \n",
       "271                0  \n",
       "..               ...  \n",
       "321                0  \n",
       "364                1  \n",
       "412                0  \n",
       "201                1  \n",
       "336                0  \n",
       "\n",
       "[100 rows x 8 columns]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test_vote['Prediction_soft'] = (pred_test_vote[['DT_soft','ET_soft','SVC_soft']].mean(axis=1) >=0.5).astype(int)\n",
    "pred_test_vote.sample(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the best param we keep the following\n",
    "X = train_df[['Pclass', 'Sex','Age','SibSp','Parch','Fare']]\n",
    "y = train_df['Survived']\n",
    "X_sub = test_df[['Pclass', 'Sex','Age','SibSp','Parch','Fare']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest parameters\n",
    "rf_params = {\n",
    "    'n_estimators': range(49,50),\n",
    "    'max_depth': range(1,5),\n",
    "    'min_samples_leaf': range(2,5),\n",
    "    'min_samples_split':range(2,5),\n",
    "}\n",
    "\n",
    "#LG Parameters\n",
    "lg_params = {\n",
    "    'C':[0.01,.1,1,2,5]\n",
    "}\n",
    "\n",
    "# Decision Trees Parameters\n",
    "dt_params = {\n",
    "    'max_depth': range(1,5),\n",
    "    'min_samples_leaf': range(2,5),\n",
    "    'min_samples_split':range(2,5),\n",
    "}\n",
    "# Extra Trees Parameters\n",
    "et_params = {\n",
    "    'max_depth': range(1,5),\n",
    "    'min_samples_leaf': range(2,5),\n",
    "    'min_samples_split':range(2,5),\n",
    "}\n",
    "\n",
    "# AdaBoost parameters\n",
    "ada_params = {\n",
    "    'n_estimators': range(49,50),\n",
    "    'learning_rate':[0.01,0.05,0.1,0.5,1]\n",
    "}\n",
    "\n",
    "\n",
    "# Support Vector Classifier parameters \n",
    "svc_params = {\n",
    "    'C' : [0,1, 0.05,0.025]\n",
    "    }\n",
    "\n",
    "knn_params = {\n",
    "    'n_neighbors':[1,2,5,10,20,30], \n",
    "    'p':[1,2],\n",
    "    'weights':['uniform','distance']\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "classifiers_names = {'RF': 'RandomForestClassifier',\n",
    "               'DT': 'DecisionTreeClassifier',\n",
    "               'LG': 'LogisticRegression',\n",
    "               'ET': 'ExtraTreesClassifier',\n",
    "               'ADA': 'AdaBoostClassifier',\n",
    "               'SVC': 'SVC',\n",
    "               'KNN': 'KNeighborsClassifier'\n",
    "\n",
    "              }\n",
    "classifiers_params = {'RF': 'rf_params',\n",
    "               'DT': 'dt_params',\n",
    "               'LG': 'lg_params',\n",
    "               'ET': 'et_params',\n",
    "               'ADA': 'ada_params',\n",
    "               'SVC': 'svc_params',\n",
    "               'KNN': 'knn_params'\n",
    "\n",
    "              }\n",
    "\n",
    "classifiers_clf = {}\n",
    "\n",
    "for key in classifiers_names:\n",
    "    classifiers_clf[key] = eval(classifiers_names[key]+'()') # RandomForestClassifier()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: RF\n",
      "Best params are: {'max_depth': 4, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 49}\n",
      "Best estimation score : 0.8248823049400539\n",
      "Best estimation variance 0.03240238785440985 \n",
      "\n",
      "Classifier: DT\n",
      "Best params are: {'max_depth': 3, 'min_samples_leaf': 3, 'min_samples_split': 2}\n",
      "Best estimation score : 0.8181658401858014\n",
      "Best estimation variance 0.032567502513050496 \n",
      "\n",
      "Classifier: LG\n",
      "Best params are: {'C': 0.1}\n",
      "Best estimation score : 0.7968300797187873\n",
      "Best estimation variance 0.036088869955324863 \n",
      "\n",
      "Classifier: ET\n",
      "Best params are: {'max_depth': 4, 'min_samples_leaf': 2, 'min_samples_split': 2}\n",
      "Best estimation score : 0.809189630280585\n",
      "Best estimation variance 0.03043478347137055 \n",
      "\n",
      "Classifier: ADA\n",
      "Best params are: {'learning_rate': 1, 'n_estimators': 49}\n",
      "Best estimation score : 0.8058125666938674\n",
      "Best estimation variance 0.038798301231628224 \n",
      "\n",
      "Classifier: SVC\n",
      "Best params are: {'C': 1}\n",
      "Best estimation score : 0.679047140794677\n",
      "Best estimation variance 0.02873598706890288 \n",
      "\n",
      "Classifier: KNN\n",
      "Best params are: {'n_neighbors': 20, 'p': 1, 'weights': 'distance'}\n",
      "Best estimation score : 0.7441403552821543\n",
      "Best estimation variance 0.033349011813676645 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Search for best parameters.\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "\n",
    "classifiers_gs = {}\n",
    "\n",
    "for key in classifiers_clf:\n",
    "    print('Classifier:',key)\n",
    "    clf = eval(classifiers_names[key]+'()')\n",
    "    params = eval(classifiers_params[key])\n",
    "    classifiers_gs[key] = GridSearchCV(clf, param_grid=params, cv=cv,n_jobs=-1)\n",
    "    _ = classifiers_gs[key].fit(X,y)\n",
    "    print('Best params are:',classifiers_gs[key].best_params_)\n",
    "    i = np.argmin(classifiers_gs[key].cv_results_['rank_test_score']) #index of min\n",
    "    print('Best estimation score :', classifiers_gs[key].best_score_)\n",
    "    print('Best estimation variance',classifiers_gs[key].cv_results_['std_test_score'][i],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_stack = {}\n",
    "pred_train_stack = pd.DataFrame(data=np.arange(X.shape[0]*len(classifiers_gs.keys())).reshape(X.shape[0],len(classifiers_gs.keys())),columns=classifiers_gs.keys())\n",
    "\n",
    "for key in classifiers_gs:\n",
    "    pred_test_stack[key] = pd.DataFrame()\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "\n",
    "\n",
    "for key in classifiers_gs:\n",
    "    fold=0\n",
    "    for train_index, test_index in cv.split(X, y):\n",
    "        X_train = X.loc[train_index]\n",
    "        y_train = y.loc[train_index]\n",
    "\n",
    "        X_test = X.loc[test_index]\n",
    "        y_test = y.loc[test_index]\n",
    "        \n",
    "        params = classifiers_gs[key].best_params_\n",
    "        model = eval(classifiers_names[key]+'(**params)')\n",
    "        model.fit( X_train,  y_train)\n",
    "\n",
    "        pred_train_stack[key][test_index] = model.predict(X_test)\n",
    "        pred_sub   = model.predict(X_sub)\n",
    "        pred_test_stack[key]['fold_'+str(fold)] = pred_sub\n",
    "\n",
    "        fold +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RF</th>\n",
       "      <th>DT</th>\n",
       "      <th>LG</th>\n",
       "      <th>ET</th>\n",
       "      <th>ADA</th>\n",
       "      <th>SVC</th>\n",
       "      <th>KNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     RF  DT  LG  ET  ADA  SVC  KNN\n",
       "0     0   0   0   0    0    0    0\n",
       "1     1   1   1   1    1    1    1\n",
       "2     1   1   1   1    1    0    1\n",
       "3     1   1   1   1    1    1    1\n",
       "4     0   0   0   0    0    0    0\n",
       "..   ..  ..  ..  ..  ...  ...  ...\n",
       "886   0   0   0   0    0    0    0\n",
       "887   1   1   1   1    1    0    1\n",
       "888   0   1   0   1    1    0    0\n",
       "889   0   0   1   0    0    0    1\n",
       "890   0   0   0   0    0    0    0\n",
       "\n",
       "[891 rows x 7 columns]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_train_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Majority voting strategy and bagging\n",
    "pred=pd.DataFrame()\n",
    "for key in pred_test_stack:\n",
    "    pred[key] = pred_test_stack[key].sum(axis=1)>2\n",
    "    pred[key] = pred[key].map({True:1,False:0})\n",
    "    \n",
    "predictions = (pred.mean(axis=1) >=0.5).astype(int)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 0 1 0 1 0 0 0 1 0 1 1 0 0 1 0 0 0 1 1 1 0 1 0 0 0 0 0 1 0 0 0 1\n",
      " 1 0 0 0 0 0 1 1 0 0 0 1 1 1 0 1 1 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 1 0 1 0\n",
      " 1 0 0 1 0 1 1 0 0 0 0 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 1 1 0 1 1 0 1 0 0 1 0 0 1 1 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1 1 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0\n",
      " 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 1 1 1 1 1 0 0 1 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 0 0 0 1 0 1 0 0 1 0 1 1 0 1 0 0 1 1 0\n",
      " 0 1 0 0 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 1 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0\n",
      " 0 1 1 1 1 1 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#Majority voting strategy\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\n",
    "\n",
    "eclf1 = VotingClassifier(estimators=classifiers_gs.items(), voting='hard')\n",
    "eclf1 = eclf1.fit(X, y)\n",
    "predictions = eclf1.predict(sub_test) \n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "feature_names mismatch: ['RF', 'DT', 'LG', 'ET', 'ADA', 'SVC', 'KNN'] []\nexpected ADA, DT, LG, KNN, ET, RF, SVC in input data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-193-812e19648859>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mclf_gbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_train_stack\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf_gbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m         \u001b[1;31m# update the docstring of the returned function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    475\u001b[0m         \"\"\"\n\u001b[0;32m    476\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'predict'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mif_delegate_has_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'best_estimator_'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'estimator'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\courses\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, output_margin, ntree_limit, validate_features)\u001b[0m\n\u001b[0;32m    789\u001b[0m                                                  \u001b[0moutput_margin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_margin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    790\u001b[0m                                                  \u001b[0mntree_limit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mntree_limit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 791\u001b[1;33m                                                  validate_features=validate_features)\n\u001b[0m\u001b[0;32m    792\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    793\u001b[0m             \u001b[1;31m# If output_margin is active, simply return the scores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\courses\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, output_margin, ntree_limit, pred_leaf, pred_contribs, approx_contribs, pred_interactions, validate_features)\u001b[0m\n\u001b[0;32m   1282\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1283\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalidate_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1284\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1286\u001b[0m         \u001b[0mlength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_bst_ulong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\courses\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_validate_features\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1689\u001b[0m                 raise ValueError(msg.format(self.feature_names,\n\u001b[1;32m-> 1690\u001b[1;33m                                             data.feature_names))\n\u001b[0m\u001b[0;32m   1691\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1692\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_split_value_histogram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_pandas\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: feature_names mismatch: ['RF', 'DT', 'LG', 'ET', 'ADA', 'SVC', 'KNN'] []\nexpected ADA, DT, LG, KNN, ET, RF, SVC in input data"
     ]
    }
   ],
   "source": [
    "# Stacking\n",
    "gbm = xgb.XGBClassifier(\n",
    "    #learning_rate = 0.02,\n",
    " n_estimators= 500,\n",
    " max_depth= 4,\n",
    " min_child_weight= 2,\n",
    " #gamma=1,\n",
    " gamma=0.9,                        \n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread= -1,\n",
    " scale_pos_weight=1)\n",
    "\n",
    "clf_gbm = GridSearchCV(gbm,param_grid=gb_params,cv=cv, n_jobs=-1)\n",
    "\n",
    "clf_gbm.fit(pred_train_stack, y)\n",
    "\n",
    "predictions = clf_gbm.predict(pred)\n",
    "\n",
    "predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_gbm.return_train_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_final_sub = pd.read_csv('.\\\\titanic\\\\test.csv')[['PassengerId']]\n",
    "my_final_sub['Survived'] = predictions\n",
    "\n",
    "my_final_sub.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
