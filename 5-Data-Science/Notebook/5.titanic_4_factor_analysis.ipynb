{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data analysis and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "# visualization\n",
    "import pydotplus\n",
    "from sklearn.tree import export_graphviz\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "\n",
    "# machine learning\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "\n",
    "#preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Acquire data\n",
    "\n",
    "The Python Pandas packages helps us work with our datasets. We start by acquiring the training and testing datasets into Pandas DataFrames. We also combine these datasets to run certain operations on both datasets together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('.\\\\titanic\\\\train.csv')\n",
    "test_data = pd.read_csv('.\\\\titanic\\\\test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Exploratory Data Analysis\n",
    "\n",
    "# III. Let's build our first model : baseline\n",
    "\n",
    "# IV. Let's build improve our model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## a. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_data.copy()\n",
    "test_df = test_data.copy()\n",
    "\n",
    "#Preprocessing : with mean for train\n",
    "train_df['Age'].fillna(train_df['Age'].mean(),inplace=True)\n",
    "train_df['Embarked'].fillna('X',inplace=True)\n",
    "train_df['Cabin'].fillna('XX',inplace=True)\n",
    "train_df['Sex'] = train_df['Sex'].map({'female':0,'male':1})\n",
    "\n",
    "#categories1 = [['Sex']]\n",
    "#for cat in categories1:\n",
    "#    lb = OrdinalEncoder()\n",
    "#    lb.fit(X[cat])\n",
    "#    X[cat] = lb.transform(X[cat])\n",
    "#    X_test[cat] = lb.transform(X_test[cat])\n",
    "\n",
    "    \n",
    "    \n",
    "#Preprocessing : with mean for test (don't use the statistic of the test in the train!!!!!!!)\n",
    "test_df['Age'].fillna(test_df['Age'].mean(),inplace=True)\n",
    "test_df['Embarked'].fillna('X',inplace=True)\n",
    "test_df['Cabin'].fillna('XX',inplace=True)\n",
    "test_df['Sex'] = test_df['Sex'].map({'female':0,'male':1})\n",
    "test_df['Fare'].fillna(test_df['Fare'].mean(),inplace=True)\n",
    "\n",
    "#For difference between get_dummies and OneHotEncoder\n",
    "#https://stackoverflow.com/questions/36631163/pandas-get-dummies-vs-sklearns-onehotencoder-what-are-the-pros-and-cons\n",
    "#One Hot encoding\n",
    "#categories2 = ['Embarked']\n",
    "#print(pd.get_dummies(X, columns=categories2))\n",
    "\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "encoder.fit(train_df[['Embarked']])    # Assume for simplicity all features are categorical.\n",
    "# Apply the encoder for train\n",
    "a = encoder.transform(train_df[['Embarked']])\n",
    "other = pd.DataFrame(data=a.toarray(),columns=['Embarked_1','Embarked_2','Embarked_3','Embarked_4'])\n",
    "train_df = train_df.join(other,lsuffix='_caller', rsuffix='_other')\n",
    "\n",
    "# Apply the encoder for test\n",
    "a = encoder.transform(test_df[['Embarked']])\n",
    "other = pd.DataFrame(data=a.toarray(),columns=['Embarked_1','Embarked_2','Embarked_3','Embarked_4'])\n",
    "test_df = test_df.join(other,lsuffix='_caller', rsuffix='_other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df[['Pclass', 'Sex','Age','SibSp','Parch','Fare',\n",
    "              'Embarked_1','Embarked_2','Embarked_3','Embarked_4']]\n",
    "\n",
    "sub_test = test_df[['Pclass', 'Sex','Age','SibSp','Parch','Fare',\n",
    "              'Embarked_1','Embarked_2','Embarked_3','Embarked_4']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Factor Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bartlet Test(p_value sould be near from 0):  291.60113582596244 2.541419377457986e-60\n",
      "KMO Test (should be > 0.6): 0.6029796205259037\n"
     ]
    }
   ],
   "source": [
    "#https://www.datacamp.com/community/tutorials/introduction-factor-analysis\n",
    "from factor_analyzer.factor_analyzer import calculate_bartlett_sphericity,calculate_kmo\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "\n",
    "X = train_df[['Fare','SibSp','Parch','Sex']]\n",
    "sub_test = test_df[['Fare', 'SibSp','Parch','Sex']]\n",
    "y = train_df['Survived']\n",
    "\n",
    "# Bartlettâ€™s Test of Sphericity compares an observed correlation matrix to \n",
    "# the identity matrix. Essentially it checks to see if there is a certain \n",
    "# redundancy between the variables that we can summarize with a few number of factors. \n",
    "# https://www.statology.org/a-guide-to-bartletts-test-of-sphericity/\n",
    "# https://easystats.github.io/parameters/reference/check_sphericity.html\n",
    "\n",
    "chi_square_value,p_value = calculate_bartlett_sphericity(X)\n",
    "print(\"Bartlet Test(p_value sould be near from 0): \",chi_square_value, p_value)\n",
    "\n",
    "kmo_all,kmo_model=calculate_kmo(X)\n",
    "print(\"KMO Test (should be > 0.6):\", kmo_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contribution is the initial variables\n",
      " [[ 0.14604528  0.21656252  0.36871657]\n",
      " [ 0.61304291  0.04644088  0.16288961]\n",
      " [ 0.61445101  0.36012295  0.13153666]\n",
      " [-0.10131338 -0.43648769 -0.19800565]]\n",
      "Eigne values: Important are > 1:\n",
      " [1.68733458 0.93051801 0.82114509 0.56100231]\n"
     ]
    }
   ],
   "source": [
    "#Latent variable\n",
    "#https://factor-analyzer.readthedocs.io/en/latest/factor_analyzer.html\n",
    "fa = FactorAnalyzer(rotation=\"varimax\",n_factors=3)\n",
    "fa.fit(X)\n",
    "\n",
    "#Check Eigenvalues\n",
    "ev, v = fa.get_eigenvalues()\n",
    "print(\"Contribution is the initial variables\\n\", fa.loadings_)\n",
    "print(\"Eigne values: Important are > 1:\\n\", ev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa = FactorAnalyzer(rotation=\"varimax\",n_factors=2)\n",
    "fa.fit(X)\n",
    "\n",
    "#Case 1 : only latent variables\n",
    "X = fa.transform(X)\n",
    "sub_test = fa.transform(sub_test)\n",
    "\n",
    "#https://towardsdatascience.com/why-feature-correlation-matters-a-lot-847e8ba439c4\n",
    "#https://statisticsbyjim.com/regression/multicollinearity-in-regression-analysis/\n",
    "#https://www.kaggle.com/reisel/how-to-handle-correlated-features\n",
    "#https://towardsdatascience.com/feature-selection-correlation-and-p-value-da8921bfb3cf\n",
    "\n",
    "#Case 2 : study of correlation\n",
    "#X = np.concatenate((X,fa.transform(X)),axis=1)\n",
    "#sub_test = np.concatenate((sub_test,fa.transform(sub_test)),axis=1)\n",
    "\n",
    "#X.merge(fa.transform,how='right')\n",
    "#pd.DataFrame(data=fa.transform(X))\n",
    "#A = np.concatenate(X,fa.transform(X),axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>7.334340e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.334340e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0             1\n",
       "0  1.000000e+00  7.334340e-09\n",
       "1  7.334340e-09  1.000000e+00"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data=X).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5,random_state=10,shuffle=True)\n",
    "\n",
    "results_df_test = pd.DataFrame()\n",
    "results_df_train = pd.DataFrame(data=np.zeros((5,2)),columns=['Train_error', 'Test_error'])\n",
    "\n",
    "fold=0\n",
    "\n",
    "for train_index, test_index in cv.split(X, y):\n",
    "    X_train = X[train_index]\n",
    "    y_train = y[train_index]\n",
    "\n",
    "    X_test = X[test_index]\n",
    "    y_test = y[test_index]\n",
    "\n",
    "    model = DecisionTreeClassifier(max_depth=7, min_samples_leaf=2)\n",
    "    model.fit( X_train,  y_train)\n",
    "\n",
    "    pred_sub   = model.predict_proba(sub_test)[:,1]\n",
    "    results_df_test['fold_'+str(fold)] = pred_sub\n",
    "    \n",
    "    pred_train = model.predict(X_train)\n",
    "    pred_test = model.predict(X_test)\n",
    "    \n",
    "    score = 1 - accuracy_score(y_train,pred_train)\n",
    "    results_df_train.loc[fold,'Train_error'] = round(score*100,2)\n",
    "    \n",
    "    score = 1 - accuracy_score(y_test,pred_test)    \n",
    "    results_df_train.loc[fold,'Test_error'] = round(score*100,2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    fold +=1\n",
    "\n",
    "#Mean strategy\n",
    "preds = (results_df.mean(axis=1) >=0.5).astype(int)\n",
    "\n",
    "my_final_sub = pd.read_csv('.\\\\titanic\\\\test.csv')[['PassengerId']]\n",
    "my_final_sub['Survived'] = preds\n",
    "\n",
    "my_final_sub.to_csv('submission_fa.csv', index=False)\n",
    "#Kaggle Score : 0.76076"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14927048260381592"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-model.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Train_error    14.086\n",
       "Test_error     19.416\n",
       "dtype: float64"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_train.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.24036259, 0.75963741])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Two variables : acc = 0.149, Train_error = 14.086, Test_error = 19.864\n",
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
